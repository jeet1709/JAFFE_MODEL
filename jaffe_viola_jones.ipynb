{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import dlib\n",
    "import pywt\n",
    "import os\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D,MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation,Dense,Flatten\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '/home/vishwajeet/Documents/Summer_Project_FER/Viola-Jones_jaffe/dataset1/'\n",
    "preprocessing_folder = '/home/vishwajeet/Documents/Summer_Project_FER/Viola-Jones_jaffe/images_with_neutral/'\n",
    "expres_code = ['NE','HA','AN','DI','FE','SA','SU']\n",
    "expressions = [ 0,   1,   2,   3,   4,   5,   6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector =cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "def preprocessing(dir_path):\n",
    "    img_list = os.listdir(dir_path)\n",
    "    count=0\n",
    "    for img in img_list:\n",
    "        input_img = cv2.imread(dir_path + img)\n",
    "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        label = img[3:5]  # each name of image have 2 char for label from index 3-5\n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detector.detectMultiScale(input_img, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(input_img, (x,y), (x+w,y+h), (0,0,0), 2)     \n",
    "            count += 1\n",
    "            face_roi=input_img[y:y+h,x:x+w]\n",
    "            face_roi = cv2.resize(face_roi,(128,128))\n",
    "        # Save the captured image into the datasets folder\n",
    "            cv2.imwrite(\"/home/vishwajeet/Documents/Summer_Project_FER/Viola-Jones_jaffe/dataset1/img.\" + str(label) + '.' +  \n",
    "                    str(count) + \".jpg\",face_roi )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing(preprocessing_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir_path):\n",
    "    img_names = []\n",
    "    img_data_list = []\n",
    "    labels = []\n",
    "    img_list = os.listdir(dir_path)\n",
    "    for img in img_list:\n",
    "        input_img = cv2.imread(dir_path + img, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data_list.append(input_img)\n",
    "        label = img[4:6]  # each name of image have 2 char for label from index 3-5\n",
    "        labels.append(expres_code.index(label))\n",
    "        img_names.append(img)\n",
    "    img_data = np.array(img_data_list)\n",
    "    print(img_data)\n",
    "    return img_data, labels, img_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   1   0 ...   0   1   0]\n",
      "  [  2  29  63 ...  68  65  10]\n",
      "  [  0  56 131 ... 142 139  23]\n",
      "  ...\n",
      "  [  0  42  87 ... 129 130  16]\n",
      "  [  0  39  83 ... 132 128  22]\n",
      "  [  2   5  13 ...  22  21   4]]\n",
      "\n",
      " [[  2   0   0 ...   2   0   0]\n",
      "  [  0   7  26 ...  37  44   6]\n",
      "  [  4  26  65 ... 110 111  11]\n",
      "  ...\n",
      "  [  0  18  53 ... 116 113  13]\n",
      "  [  0  20  48 ... 115 111  13]\n",
      "  [  1   2   6 ...  14  11   1]]\n",
      "\n",
      " [[  1   0   0 ...   0   0   0]\n",
      "  [  0  16  55 ...   0   0   0]\n",
      "  [  0  55 165 ...   2   1   0]\n",
      "  ...\n",
      "  [  0  35 103 ...   4   4   0]\n",
      "  [  0  44 103 ...   4   4   2]\n",
      "  [  1   1   9 ...   0   1   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   1 ...   1   0   0]\n",
      "  [  0   3   7 ...   4  14   1]\n",
      "  [  0   6  11 ...  12  33   6]\n",
      "  ...\n",
      "  [  0  20  79 ... 141 145  11]\n",
      "  [  0  24  80 ... 146 145  14]\n",
      "  [  1   0   8 ...  11  13   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   1   1]\n",
      "  [  3  19  46 ...  45  40   3]\n",
      "  [  0  48 117 ... 102 104  20]\n",
      "  ...\n",
      "  [  0   0   2 ...   3   3   0]\n",
      "  [  0   1   2 ...   3   3   0]\n",
      "  [  0   1   1 ...   0   1   0]]\n",
      "\n",
      " [[  0   2   0 ...   2   0   0]\n",
      "  [  2  16  34 ...  35  36   7]\n",
      "  [  0  37  95 ... 100  95  11]\n",
      "  ...\n",
      "  [  0   2   3 ...   5   3   0]\n",
      "  [  0   1   2 ...   4   2   0]\n",
      "  [  0   0   1 ...   1   1   0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(213, 128, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, img_names = read_data(train_folder)\n",
    "img_x=np.array(X)\n",
    "img_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_encoding = pd.get_dummies(Y, sparse=True)\n",
    "labelenc= np.asarray(labels_encoding)\n",
    "# print(labelenc.shape)\n",
    "# print(labelenc[:43])\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_x, \n",
    "                                                    labelenc, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=np.array(labelenc), \n",
    "                                                    random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 128, 128, 1), (43, 128, 128, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=128\n",
    "cols=128\n",
    "x_train=x_train.reshape(x_train.shape[0],rows,cols,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],rows,cols,1)\n",
    "\n",
    "input_shape=(rows,cols,1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 2.0372 - accuracy: 0.1765\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.9973 - accuracy: 0.1706\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 1.9441 - accuracy: 0.1471\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.9270 - accuracy: 0.2471\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 1.9069 - accuracy: 0.2471\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 4s 26ms/step - loss: 1.8828 - accuracy: 0.2588\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 1.8034 - accuracy: 0.3471\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 1.6708 - accuracy: 0.4294\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 1.4454 - accuracy: 0.5118\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 1.4243 - accuracy: 0.4824\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 1.1744 - accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 1.1075 - accuracy: 0.6294\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 1.0083 - accuracy: 0.6529\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.8311 - accuracy: 0.7118\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 0.8208 - accuracy: 0.6941\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.7059 - accuracy: 0.7529\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.5216 - accuracy: 0.8118\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.4518 - accuracy: 0.8471\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.4119 - accuracy: 0.8529\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.3835 - accuracy: 0.8647\n",
      "Epoch 21/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.2798 - accuracy: 0.9000\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 0.2560 - accuracy: 0.9353\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.2262 - accuracy: 0.9059\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.2632 - accuracy: 0.8824\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.1486 - accuracy: 0.9588\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.2382 - accuracy: 0.9353\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.1614 - accuracy: 0.9529\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.1396 - accuracy: 0.9471\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.1332 - accuracy: 0.9706\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.1459 - accuracy: 0.9412\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.1068 - accuracy: 0.9588\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0969 - accuracy: 0.9588\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.0967 - accuracy: 0.9706\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0946 - accuracy: 0.9588\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.1037 - accuracy: 0.9647\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.0626 - accuracy: 0.9706\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0730 - accuracy: 0.9882\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.0599 - accuracy: 0.9882\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0426 - accuracy: 0.9882\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.0613 - accuracy: 0.9706\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0840 - accuracy: 0.9765\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0619 - accuracy: 0.9706\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0700 - accuracy: 0.9824\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0546 - accuracy: 0.9647\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0823 - accuracy: 0.9647\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0660 - accuracy: 0.9765\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0394 - accuracy: 0.9882\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0438 - accuracy: 0.9882\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.0751 - accuracy: 0.9824\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.0468 - accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\",optimizer = Adam(), metrics=['accuracy'],)\n",
    "BATCH_SIZE=85\n",
    "epochs=50\n",
    "\n",
    "model.fit(x_train, y_train,epochs=epochs, batch_size=BATCH_SIZE,verbose=1)\n",
    "\n",
    "model.save('jaffe_model_viola_jones.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 23ms/step\n",
      "ACCURACY:  0.8372092843055725\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"jaffe_model_viola_jones.h5\")\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",optimizer = Adam(), metrics=['accuracy'],)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('ACCURACY: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 0 0 0 1 0]\n",
      " [0 6 0 0 0 0 0]\n",
      " [0 0 3 2 0 1 0]\n",
      " [0 0 0 5 1 0 0]\n",
      " [1 0 0 0 6 0 0]\n",
      " [0 0 0 1 0 5 0]\n",
      " [0 0 0 0 0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict_classes(x_test)\n",
    "y_test_original=np.argmax(y_test,axis=1)\n",
    "confusion=confusion_matrix(y_true=y_test_original, y_pred=y_prediction)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 1799      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 13,216,775\n",
      "Trainable params: 13,216,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
